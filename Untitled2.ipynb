{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10, 90)\n",
      "(?, 1, 6)\n",
      "111111111111111111111111111111111111111111111111111\n",
      "(?, 10, 90)\n",
      "(?, 10, 6)\n",
      "111111111111111111111111111111111111111111111111111\n",
      "('_video_ind = ', '098', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '099', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '214', 'per_video_db.shape = ', (28, 10, 90))\n",
      "('_video_ind = ', '215', 'per_video_db.shape = ', (58, 10, 90))\n",
      "('_video_ind = ', '212', 'per_video_db.shape = ', (84, 10, 90))\n",
      "('_video_ind = ', '213', 'per_video_db.shape = ', (29, 10, 90))\n",
      "('_video_ind = ', '210', 'per_video_db.shape = ', (28, 10, 90))\n",
      "('_video_ind = ', '211', 'per_video_db.shape = ', (29, 10, 90))\n",
      "('_video_ind = ', '090', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '092', 'per_video_db.shape = ', (102, 10, 90))\n",
      "('_video_ind = ', '093', 'per_video_db.shape = ', (68, 10, 90))\n",
      "video 094 only has 17 seconds. skip...\n",
      "('_video_ind = ', '095', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '096', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '097', 'per_video_db.shape = ', (136, 10, 90))\n",
      "('_video_ind = ', '133', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '011', 'per_video_db.shape = ', (33, 10, 90))\n",
      "video 012 only has 18 seconds. skip...\n",
      "('_video_ind = ', '130', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '014', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '015', 'per_video_db.shape = ', (66, 10, 90))\n",
      "('_video_ind = ', '016', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '134', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '018', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '139', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '138', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '025', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '122', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '026', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '021', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '125', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '023', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '127', 'per_video_db.shape = ', (238, 10, 90))\n",
      "('_video_ind = ', '129', 'per_video_db.shape = ', (102, 10, 90))\n",
      "('_video_ind = ', '029', 'per_video_db.shape = ', (33, 10, 90))\n",
      "video 010 only has 18 seconds. skip...\n",
      "('_video_ind = ', '132', 'per_video_db.shape = ', (102, 10, 90))\n",
      "('_video_ind = ', '131', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '013', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '137', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '199', 'per_video_db.shape = ', (87, 10, 90))\n",
      "('_video_ind = ', '135', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '200', 'per_video_db.shape = ', (29, 10, 90))\n",
      "('_video_ind = ', '195', 'per_video_db.shape = ', (120, 10, 90))\n",
      "('_video_ind = ', '194', 'per_video_db.shape = ', (31, 10, 90))\n",
      "video 197 only has 18 seconds. skip...\n",
      "('_video_ind = ', '017', 'per_video_db.shape = ', (66, 10, 90))\n",
      "('_video_ind = ', '191', 'per_video_db.shape = ', (93, 10, 90))\n",
      "('_video_ind = ', '089', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '193', 'per_video_db.shape = ', (93, 10, 90))\n",
      "('_video_ind = ', '115', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '114', 'per_video_db.shape = ', (136, 10, 90))\n",
      "('_video_ind = ', '117', 'per_video_db.shape = ', (102, 10, 90))\n",
      "('_video_ind = ', '116', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '111', 'per_video_db.shape = ', (102, 10, 90))\n",
      "('_video_ind = ', '110', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '113', 'per_video_db.shape = ', (136, 10, 90))\n",
      "('_video_ind = ', '112', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '033', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '030', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '119', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '056', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '034', 'per_video_db.shape = ', (33, 10, 90))\n",
      "('_video_ind = ', '035', 'per_video_db.shape = ', (29, 10, 90))\n",
      "('_video_ind = ', '057', 'per_video_db.shape = ', (90, 10, 90))\n",
      "('_video_ind = ', '173', 'per_video_db.shape = ', (64, 10, 90))\n",
      "('_video_ind = ', '172', 'per_video_db.shape = ', (128, 10, 90))\n",
      "('_video_ind = ', '052', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '053', 'per_video_db.shape = ', (120, 10, 90))\n",
      "video 109 only has 17 seconds. skip...\n",
      "('_video_ind = ', '085', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '049', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '048', 'per_video_db.shape = ', (30, 10, 90))\n",
      "video 102 only has 11 seconds. skip...\n",
      "('_video_ind = ', '046', 'per_video_db.shape = ', (60, 10, 90))\n",
      "('_video_ind = ', '045', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '044', 'per_video_db.shape = ', (90, 10, 90))\n",
      "('_video_ind = ', '106', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '042', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '104', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '105', 'per_video_db.shape = ', (136, 10, 90))\n",
      "('_video_ind = ', '177', 'per_video_db.shape = ', (32, 10, 90))\n",
      "('_video_ind = ', '076', 'per_video_db.shape = ', (238, 10, 90))\n",
      "video 077 only has 19 seconds. skip...\n",
      "('_video_ind = ', '176', 'per_video_db.shape = ', (64, 10, 90))\n",
      "('_video_ind = ', '144', 'per_video_db.shape = ', (62, 10, 90))\n",
      "('_video_ind = ', '152', 'per_video_db.shape = ', (64, 10, 90))\n",
      "('_video_ind = ', '059', 'per_video_db.shape = ', (60, 10, 90))\n",
      "('_video_ind = ', '179', 'per_video_db.shape = ', (90, 10, 90))\n",
      "('_video_ind = ', '178', 'per_video_db.shape = ', (96, 10, 90))\n",
      "('_video_ind = ', '054', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '055', 'per_video_db.shape = ', (60, 10, 90))\n",
      "('_video_ind = ', '175', 'per_video_db.shape = ', (96, 10, 90))\n",
      "('_video_ind = ', '174', 'per_video_db.shape = ', (96, 10, 90))\n",
      "('_video_ind = ', '050', 'per_video_db.shape = ', (90, 10, 90))\n",
      "('_video_ind = ', '051', 'per_video_db.shape = ', (60, 10, 90))\n",
      "('_video_ind = ', '171', 'per_video_db.shape = ', (64, 10, 90))\n",
      "('_video_ind = ', '198', 'per_video_db.shape = ', (87, 10, 90))\n",
      "video 070 only has 19 seconds. skip...\n",
      "('_video_ind = ', '071', 'per_video_db.shape = ', (150, 10, 90))\n",
      "('_video_ind = ', '145', 'per_video_db.shape = ', (64, 10, 90))\n",
      "('_video_ind = ', '182', 'per_video_db.shape = ', (62, 10, 90))\n",
      "('_video_ind = ', '183', 'per_video_db.shape = ', (62, 10, 90))\n",
      "('_video_ind = ', '180', 'per_video_db.shape = ', (31, 10, 90))\n",
      "('_video_ind = ', '181', 'per_video_db.shape = ', (93, 10, 90))\n",
      "('_video_ind = ', '186', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '041', 'per_video_db.shape = ', (90, 10, 90))\n",
      "('_video_ind = ', '184', 'per_video_db.shape = ', (93, 10, 90))\n",
      "('_video_ind = ', '188', 'per_video_db.shape = ', (31, 10, 90))\n",
      "('_video_ind = ', '040', 'per_video_db.shape = ', (120, 10, 90))\n",
      "('_video_ind = ', '187', 'per_video_db.shape = ', (93, 10, 90))\n",
      "('_video_ind = ', '060', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '063', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '196', 'per_video_db.shape = ', (60, 10, 90))\n",
      "('_video_ind = ', '065', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '064', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '067', 'per_video_db.shape = ', (90, 10, 90))\n",
      "('_video_ind = ', '066', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '069', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '068', 'per_video_db.shape = ', (90, 10, 90))\n",
      "('_video_ind = ', '168', 'per_video_db.shape = ', (32, 10, 90))\n",
      "('_video_ind = ', '164', 'per_video_db.shape = ', (96, 10, 90))\n",
      "('_video_ind = ', '165', 'per_video_db.shape = ', (96, 10, 90))\n",
      "video 166 only has 19 seconds. skip...\n",
      "('_video_ind = ', '167', 'per_video_db.shape = ', (32, 10, 90))\n",
      "video 162 only has 19 seconds. skip...\n",
      "('_video_ind = ', '163', 'per_video_db.shape = ', (96, 10, 90))\n",
      "('_video_ind = ', '189', 'per_video_db.shape = ', (31, 10, 90))\n",
      "('_video_ind = ', '038', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '039', 'per_video_db.shape = ', (60, 10, 90))\n",
      "('_video_ind = ', '151', 'per_video_db.shape = ', (96, 10, 90))\n",
      "('_video_ind = ', '150', 'per_video_db.shape = ', (32, 10, 90))\n",
      "('_video_ind = ', '074', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '075', 'per_video_db.shape = ', (68, 10, 90))\n",
      "('_video_ind = ', '072', 'per_video_db.shape = ', (66, 10, 90))\n",
      "('_video_ind = ', '073', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '157', 'per_video_db.shape = ', (32, 10, 90))\n",
      "('_video_ind = ', '156', 'per_video_db.shape = ', (64, 10, 90))\n",
      "('_video_ind = ', '159', 'per_video_db.shape = ', (32, 10, 90))\n",
      "('_video_ind = ', '078', 'per_video_db.shape = ', (136, 10, 90))\n",
      "('_video_ind = ', '062', 'per_video_db.shape = ', (90, 10, 90))\n",
      "('_video_ind = ', '100', 'per_video_db.shape = ', (34, 10, 90))\n",
      "('_video_ind = ', '037', 'per_video_db.shape = ', (30, 10, 90))\n",
      "('_video_ind = ', '147', 'per_video_db.shape = ', (64, 10, 90))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-495715dd9c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0m_video_db\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_video_db_future\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_video_db_future_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpick_user\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;31m# total_num_samples = _video_db.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maojuntao/Downloads/project/utility.pyc\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(datadb, pick_user, num_user)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mper_video_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_video_db_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_video_db_future_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape2second_stacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_video_db\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcollapse_user\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_video_ind = '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_video_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'per_video_db.shape = '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_video_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0m_video_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_video_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_video_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0m_video_db_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_video_db_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_video_db_future\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-first part:\n",
    "seq2seq without teacher forcing\n",
    "-second part:\n",
    "seq2seq without teacher forcing, with others' future convLSTM\n",
    "concat states with decoder LSTM and then predict\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.layers import Lambda,Concatenate,Flatten,ConvLSTM2D\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import sys,glob,io,random\n",
    "if '/Users/maojuntao/Downloads/project/' not in sys.path:\n",
    "    sys.path.insert(0, '/Users/maojuntao/Downloads/project/')\n",
    "from dataLayer import DataLayer\n",
    "import cost as costfunc\n",
    "from config import cfg\n",
    "from dataIO import clip_xyz\n",
    "from utility import reshape2second_stacks,get_data\n",
    "from utility import get_shuffle_index,shuffle_data,get_gt_target_xyz,get_gt_target_xyz_oth\n",
    "from utility import slice_layer\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pdb\n",
    "### ====================Graph def====================\n",
    "def onelayer_tar_seq2seq():\n",
    "    # The first part is unchanged\n",
    "    if not cfg.input_mean_var:\n",
    "        encoder_inputs = Input(shape=(10, num_encoder_tokens))\n",
    "    else:\n",
    "        encoder_inputs = Input(shape=(None, num_decoder_tokens))    \n",
    "    print(encoder_inputs.shape)\n",
    "    encoder = LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, which will only process one timestep at a time.\n",
    "    decoder_inputs = Input(shape=(1, num_decoder_tokens))\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_dense = Dense(num_decoder_tokens,activation='tanh')\n",
    "\n",
    "    all_outputs = []\n",
    "    inputs = decoder_inputs\n",
    "    for _ in range(max_decoder_seq_length):\n",
    "        # Run the decoder on one timestep\n",
    "        decoder_states, state_h, state_c = decoder_lstm(inputs,\n",
    "                                                 initial_state=states)\n",
    "        outputs = decoder_dense(decoder_states)\n",
    "        # Store the current prediction (we will concatenate all predictions later)\n",
    "        all_outputs.append(outputs)\n",
    "        # Reinject the outputs as inputs for the next loop iteration\n",
    "        # as well as update the states\n",
    "        inputs = outputs\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    print((all_outputs[0].shape))\n",
    "    print(\"111111111111111111111111111111111111111111111111111\")\n",
    "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "    \n",
    "    # Define and compile model as previously\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    print((encoder_inputs.shape))\n",
    "    print((decoder_outputs.shape))\n",
    "    print(\"111111111111111111111111111111111111111111111111111\")\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #experiment = 1\n",
    "    batch_size = 32  # Batch size for training.\n",
    "    epochs = 200  # Number of epochs to train for.\n",
    "    latent_dim = 64  # Latent dimensionality of the encoding space.\n",
    "\n",
    "    fps = 30\n",
    "    num_encoder_tokens = 3*fps\n",
    "    num_decoder_tokens = 6\n",
    "    max_encoder_seq_length = cfg.running_length\n",
    "    max_decoder_seq_length = cfg.predict_step\n",
    "    # num_user = 48\n",
    "\n",
    "\n",
    "    model = onelayer_tar_seq2seq()\n",
    "    model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "\n",
    "    #### ====================data====================\n",
    "    ## load data just as in Fov_seq2seq.py\n",
    "    # if cfg.use_xyz:\n",
    "    #     all_video_data = pickle.load(open('/scratch/cl2840/360video/data/new_exp_'+str(experiment)+'_xyz.p','rb'))\n",
    "    #     data_dim = 3\n",
    "    # all_video_data = clip_xyz(all_video_data)\n",
    "    # datadb = all_video_data.copy()\n",
    "    ##### data format 3or4--4\n",
    "    # video_data_train = pickle.load(open('/scratch/cl2840/360video/data/shanghai_dataset_xyz_train.p','rb'))    \n",
    "    #### format5\n",
    "    video_data_train = pickle.load(open('/Users/maojuntao/Downloads/project/data 2/shanghai_dataset_xyz_train.p','rb')) \n",
    "    video_data_train = clip_xyz(video_data_train)\n",
    "    datadb = video_data_train.copy()\n",
    "\n",
    "\n",
    "    _video_db,_video_db_future,_video_db_future_input = get_data(datadb,pick_user=False)\n",
    "    # total_num_samples = _video_db.shape[0]\n",
    "\n",
    "    if cfg.shuffle_data:\n",
    "        #shuffle the whole dataset\n",
    "        # index_shuf = get_shuffle_index(total_num_samples)\n",
    "        index_shuf = pickle.load(open('index_shuf'+'_exp'+str(experiment)+'.p','rb'))\n",
    "        _video_db = shuffle_data(index_shuf,_video_db)\n",
    "        _video_db_future = shuffle_data(index_shuf,_video_db_future)\n",
    "        _video_db_future_input = shuffle_data(index_shuf,_video_db_future_input)\n",
    "\n",
    "\n",
    "    # num_testing_sample = int(0.15*total_num_samples)#use last few as test\n",
    "    num_testing_sample = 1\n",
    "    if cfg.input_mean_var:\n",
    "        encoder_input_data = get_gt_target_xyz(_video_db[:-num_testing_sample,:,:])\n",
    "    else:\n",
    "        encoder_input_data = _video_db[:-num_testing_sample,:,:]\n",
    "    decoder_target_data = get_gt_target_xyz(_video_db_future)[:-num_testing_sample,:,:]\n",
    "    # decoder_input_data = get_gt_target_xyz(_video_db_future_input)[:-num_testing_sample,-1,:][:,np.newaxis,:]\n",
    "    decoder_input_data = get_gt_target_xyz(_video_db_future_input)[:-num_testing_sample,0,:][:,np.newaxis,:]\n",
    "\n",
    "\n",
    "\n",
    "    ### ====================Training====================\n",
    "    # model = load_model('fov_s2s_noteacherforcing_epoch21-0.0759.h5')\n",
    "    # tag = 'notFor_tanh_newdata_exp2_epoch'\n",
    "    # tag = 'fctar_seqseq_shanghai_traintest_split_predmeanvar_Aug9'\n",
    "    # tag = 'fctar_seqseq_shanghai_traintest_split_meanvarmeanvar_Aug9'\n",
    "    tag = 'fctar_seqseq_THU_predmeanvar_Sep5'\n",
    "    model_checkpoint = ModelCheckpoint(tag+'{epoch:02d}-{val_loss:.4f}.h5', monitor='val_loss', save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                     patience=3, min_lr=1e-6)\n",
    "    stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,initial_epoch=0,\n",
    "              callbacks=[model_checkpoint, reduce_lr, stopping])\n",
    "\n",
    "\n",
    "\n",
    "    ### ====================Testing====================\n",
    "    ##### data format 3or4--4\n",
    "    # video_data_test = pickle.load(open('/scratch/cl2840/360video/data/shanghai_dataset_xyz_test.p','rb'))\n",
    "    ### data format 5\n",
    "    video_data_test = pickle.load(open('/Users/maojuntao/Downloads/project/data 2/shanghai_dataset_xyz_test.p','rb'))\n",
    "\n",
    "    video_data_test = clip_xyz(video_data_test)\n",
    "    datadb = video_data_test.copy()   ##arrange the test data\n",
    "    _video_db,_video_db_future,_video_db_future_input = get_data(datadb,pick_user=False)\n",
    "\n",
    "    if cfg.input_mean_var:\n",
    "        _video_db = get_gt_target_xyz(_video_db)\n",
    "\n",
    "    # model = load_model('fov_s2s_noteacherforcing.h5')\n",
    "    # model = load_model('fov_s2s_noteacherforcing_epoch74-0.0087.h5')\n",
    "    # model = load_model('notFor_tanh_newdata_epoch18-0.0761.h5')\n",
    "    # model = load_model('notFor_tanh_newdata_exp2_epoch200-0.0302.h5')\n",
    "    def decode_sequence_fov(input_seq):\n",
    "        # Encode the input as state vectors.\n",
    "        last_location = input_seq[0,-1,:][np.newaxis,np.newaxis,:]\n",
    "        if not cfg.input_mean_var:\n",
    "            last_mu_var = get_gt_target_xyz(last_location)\n",
    "        else:\n",
    "            last_mu_var = last_location\n",
    "        decoded_sentence = model.predict([input_seq,last_mu_var])\n",
    "        return decoded_sentence\n",
    "\n",
    "\n",
    "    gt_sentence_list = []\n",
    "    decoded_sentence_list = []\n",
    "    # for seq_index in range(total_num_samples-num_testing_sample,total_num_samples):\n",
    "    for seq_index in range(_video_db.shape[0]):\n",
    "        # Take one sequence (part of the training set)\n",
    "        # for trying out decoding.\n",
    "        input_seq = _video_db[seq_index: seq_index + 1,:,:]\n",
    "\n",
    "        decoded_sentence = decode_sequence_fov(input_seq)\n",
    "        decoded_sentence_list+=[decoded_sentence]\n",
    "        gt_sentence = _video_db_future[seq_index: seq_index + 1,:,:]\n",
    "        gt_sentence_list+=[gt_sentence]\n",
    "        decoder_target = get_gt_target_xyz(gt_sentence)\n",
    "        # print('-')\n",
    "        # print('Decoded sentence - decoder_target:', np.squeeze(np.array(decoded_sentence))[:,:3]-np.squeeze(decoder_target)[:,:3])\n",
    "\n",
    "    pickle.dump(decoded_sentence_list,open('decoded_sentence'+tag+'.p','wb'))\n",
    "    pickle.dump(gt_sentence_list,open('gt_sentence_list'+tag+'.p','wb'))\n",
    "    print('Testing finished!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

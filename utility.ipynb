{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from config import cfg\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Lambda\n",
    "from keras.utils import to_categorical\n",
    "import pdb\n",
    "import random\n",
    "import h5py\n",
    "from collections import OrderedDict\n",
    "\n",
    "batch_size = cfg.batch_size\n",
    "fps = cfg.fps\n",
    "def _reshape_batchsize(tensor):\n",
    "    if cfg.predict_len>1:\n",
    "        return tf.reshape(tensor,[batch_size,cfg.predict_len,1])\n",
    "    else:\n",
    "        return tf.reshape(tensor,[batch_size,1])\n",
    "\n",
    "\n",
    "# def _filter_stuffed_fake_future_val(data_further):\n",
    "#     tf.equal(data_further,1.123)\n",
    "#     # TODO\n",
    "\n",
    "def tf_get_gt_target_xyz(y):\n",
    "    \"\"\"get gt mean var\"\"\"\n",
    "    target_x = y[:,:,0::3]\n",
    "    target_y = y[:,:,1::3]\n",
    "    target_z = y[:,:,2::3]\n",
    "    gt_mean_x, gt_var_x = tf.nn.moments(target_x, axes=[-1])\n",
    "    gt_mean_y, gt_var_y = tf.nn.moments(target_y, axes=[-1])\n",
    "    gt_mean_z, gt_var_z = tf.nn.moments(target_z, axes=[-1])\n",
    "\n",
    "    target = (_reshape_batchsize(gt_mean_x),_reshape_batchsize(gt_mean_y),_reshape_batchsize(gt_mean_z),\n",
    "                _reshape_batchsize(gt_var_x),_reshape_batchsize(gt_var_y),_reshape_batchsize(gt_var_z))\n",
    "    return target\n",
    "\n",
    "def change_input_format(batch_x,data_dim=3):\n",
    "    \"\"\"change [xyzxyz...]90*1 into [xxx...yyy...zzz..]\"\"\"\n",
    "    assert batch_x.shape[0]==batch_size\n",
    "    assert batch_x.shape[2]==data_dim\n",
    "    temp = np.concatenate((batch_x[:,:,0::3],batch_x[:,:,1::3],batch_x[:,:,2::3]),axis=-1)\n",
    "    return temp\n",
    "\n",
    "\n",
    "def get_gt_target_xyz_pop(y):\n",
    "    \"\"\"get pop mean var\"\"\"\n",
    "    target_x = tf.contrib.layers.flatten(y[:,:,:fps*1,0])\n",
    "    target_y = tf.contrib.layers.flatten(y[:,:,:fps*1,1])\n",
    "    target_z = tf.contrib.layers.flatten(y[:,:,:fps*1,2])\n",
    "    pop_mean_x, pop_var_x = tf.nn.moments(target_x, axes=[1])\n",
    "    pop_mean_y, pop_var_y = tf.nn.moments(target_y, axes=[1])\n",
    "    pop_mean_z, pop_var_z = tf.nn.moments(target_z, axes=[1])\n",
    "\n",
    "    target = (_reshape_batchsize(pop_mean_x),_reshape_batchsize(pop_mean_y),_reshape_batchsize(pop_mean_z),\n",
    "            _reshape_batchsize(pop_var_x),_reshape_batchsize(pop_var_y),_reshape_batchsize(pop_var_z))\n",
    "    return target\n",
    "\n",
    "    \n",
    "def get_gt_target_phi_theta(y):\n",
    "    \"\"\"get gt mean var\"\"\"\n",
    "    target_phi = y[:,0,0::3]\n",
    "    target_theta = y[:,0,1::3]\n",
    "    gt_mean_phi, gt_var_phi = tf.nn.moments(target_phi, axes=[1])\n",
    "    gt_mean_theta, gt_var_theta = tf.nn.moments(target_theta, axes=[1])\n",
    "\n",
    "    target = (_reshape_batchsize(gt_mean_phi),_reshape_batchsize(gt_mean_theta),\n",
    "                _reshape_batchsize(gt_var_phi),_reshape_batchsize(gt_var_theta))\n",
    "    return target\n",
    "\n",
    "\n",
    "\n",
    "def generate_fake_batch_numpy(mu,var,batch_size):\n",
    "    \"\"\"generate new data for 1 second using predicted mean and variance\"\"\"\n",
    "    # print('there are %s variance less than zero.'%str((var<0).sum()))\n",
    "    var[var<0]=1e-3\n",
    "    temp = []\n",
    "    for ii in range(batch_size):\n",
    "        temp.append(np.random.normal(mu[ii], np.sqrt(var[ii]), fps*1))\n",
    "    return temp\n",
    "\n",
    "\n",
    "def generate_fake_batch_tf(mu,var):\n",
    "    \"\"\"for tf\"\"\"\n",
    "    temp = []\n",
    "    batch_size = mu.shape[0].value\n",
    "    for ii in range(batch_size):\n",
    "        temp.append(tf.random_normal(np.array([fps,1]),mean=mu[ii], stddev=tf.sqrt(var[ii])))\n",
    "    return temp\n",
    "\n",
    "\n",
    "def generate_fake_batch_multivariate_normal_numpy(mu_theta,mu_phi,sigma_theta,sigma_phi,rho,batch_size):\n",
    "    \"\"\"generate new data for 1 second using predicted mean and covariance matrix using multivariate_normal\"\"\"\n",
    "    # print('there are %s variance less than zero.'%str((var<0).sum()))\n",
    "    # var[var<0]=1e-3\n",
    "    if cfg.process_in_seconds:\n",
    "        size = fps*1\n",
    "    else:\n",
    "        size = [int(0.5*cfg.running_length),2]#for theta,phi\n",
    "    covmat = np.array([[sigma_theta**2,rho*sigma_theta*sigma_phi],[rho*sigma_theta*sigma_phi,sigma_phi**2]])\n",
    "    temp = []\n",
    "    for ii in range(batch_size):\n",
    "        mu = [mu_theta[ii][0],mu_phi[ii][0]]\n",
    "        temp.append(np.random.multivariate_normal(mu, cov=covmat[:,:,ii,0], size=size))\n",
    "    temp = np.array(temp).reshape((batch_size,1,-1))\n",
    "    return temp\n",
    "\n",
    "\n",
    "def generate_fake_batch_mixture(mixture_pi,us,sigmas,rho):\n",
    "    \"\"\"using GMM\"\"\"\n",
    "    mu_theta = us[:,0::2]\n",
    "    mu_phi = us[:,1::2]\n",
    "    sigma_theta = sigmas[:,0::2]\n",
    "    sigma_phi = sigmas[:,1::2]\n",
    "    covmat = np.array([[sigma_theta**2,rho*sigma_theta*sigma_phi],[rho*sigma_theta*sigma_phi,sigma_phi**2]])\n",
    "    samples = []\n",
    "    if cfg.process_in_seconds:\n",
    "        size = fps*1\n",
    "    else:\n",
    "        size = int(0.5*cfg.running_length)\n",
    "    for ii in range(batch_size):\n",
    "        temp = np.zeros((size,2))\n",
    "        for mixture_ind in range(mu_theta.shape[1]):\n",
    "            temp+=mixture_pi[ii,mixture_ind]*np.random.multivariate_normal([mu_theta[ii,mixture_ind],mu_phi[ii,mixture_ind]], cov=covmat[:,:,ii,mixture_ind], size=size)\n",
    "        samples.append(temp)\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "def sample_mixture(predictions):\n",
    "    \"\"\"randomly one sample from GMM\"\"\"\n",
    "    if cfg.predict_eos:\n",
    "        end_of_stroke,mixture_pi,us,sigmas,rho = predictions\n",
    "        samples = np.zeros([batch_size, 1, 3], np.float32)\n",
    "    else:\n",
    "        mixture_pi,us,sigmas,rho = predictions\n",
    "        samples = np.zeros([batch_size, 1, 2], np.float32)        \n",
    "    mu_theta = us[:,0::2]\n",
    "    mu_phi = us[:,1::2]\n",
    "    sigma_theta = sigmas[:,0::2]\n",
    "    sigma_phi = sigmas[:,1::2]\n",
    "    r = np.random.rand()\n",
    "    for ii in range(batch_size):\n",
    "        accu = 0\n",
    "        for m in range(mu_theta.shape[1]):\n",
    "            # accu += mixture_pi[ii, m]\n",
    "            # if accu > r:\n",
    "            #     samples[ii, 0, 0:2] = np.random.multivariate_normal(\n",
    "            #         [mu_theta[ii, m], mu_phi[ii, m]],\n",
    "            #         [[np.square(sigma_theta[ii, m]), rho[ii, m] * sigma_theta[ii, m] * sigma_phi[ii, m]],\n",
    "            #         [rho[ii, m] * sigma_theta[ii, m] * sigma_phi[ii, m], np.square(sigma_phi[ii, m])]])\n",
    "            #     break\n",
    "\n",
    "            convariance_mat = [[np.square(sigma_theta[ii, m]), rho[ii, m] * sigma_theta[ii, m] * sigma_phi[ii, m]],\n",
    "                    [rho[ii, m] * sigma_theta[ii, m] * sigma_phi[ii, m], np.square(sigma_phi[ii, m])]]\n",
    "            convariance_mat = _make_positive_semidefinite(convariance_mat)\n",
    "            samples[ii, 0, 0:2] += mixture_pi[ii, m]*np.random.multivariate_normal(\n",
    "                    [mu_theta[ii, m], mu_phi[ii, m]],\n",
    "                     convariance_mat)\n",
    "            if accu > r:\n",
    "                break\n",
    "\n",
    "        if cfg.predict_eos:\n",
    "            # e = np.random.rand()\n",
    "            # if e < end_of_stroke[ii]:\n",
    "            #     samples[ii, 0, 2] = 1\n",
    "            # else:\n",
    "            #     samples[ii, 0, 2] = 0\n",
    "            if end_of_stroke[ii]>0.7:\n",
    "                samples[ii, 0, 2] = 1\n",
    "            else:\n",
    "                samples[ii, 0, 2] = 0\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_mixture_3D(predictions):\n",
    "    \"\"\"randomly one sample from 3D GMM\"\"\"\n",
    "    pdb.set_trace()\n",
    "    mixture_pi,us,sigmas,rho = predictions\n",
    "    samples = np.zeros([batch_size, 1, 2], np.float32)        \n",
    "    mu_theta = us[:,0::2]\n",
    "    mu_phi = us[:,1::2]\n",
    "    sigma_theta = sigmas[:,0::2]\n",
    "    sigma_phi = sigmas[:,1::2]\n",
    "    r = np.random.rand()\n",
    "    for ii in range(batch_size):\n",
    "        accu = 0\n",
    "        for m in range(mu_theta.shape[1]):\n",
    "            # accu += mixture_pi[ii, m]\n",
    "            # if accu > r:\n",
    "            #     samples[ii, 0, 0:2] = np.random.multivariate_normal(\n",
    "            #         [mu_theta[ii, m], mu_phi[ii, m]],\n",
    "            #         [[np.square(sigma_theta[ii, m]), rho[ii, m] * sigma_theta[ii, m] * sigma_phi[ii, m]],\n",
    "            #         [rho[ii, m] * sigma_theta[ii, m] * sigma_phi[ii, m], np.square(sigma_phi[ii, m])]])\n",
    "            #     break\n",
    "\n",
    "            convariance_mat = [[np.square(sigma_theta[ii, m]), rho[ii, m] * sigma_theta[ii, m] * sigma_phi[ii, m]],\n",
    "                    [rho[ii, m] * sigma_theta[ii, m] * sigma_phi[ii, m], np.square(sigma_phi[ii, m])]]\n",
    "            convariance_mat = _make_positive_semidefinite(convariance_mat)\n",
    "            samples[ii, 0, 0:2] += mixture_pi[ii, m]*np.random.multivariate_normal(\n",
    "                    [mu_theta[ii, m], mu_phi[ii, m]],\n",
    "                     convariance_mat)\n",
    "            if accu > r:\n",
    "                break\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "\n",
    "def _make_positive_semidefinite(convariance_mat):\n",
    "    min_eig = np.min(np.real(np.linalg.eigvals(convariance_mat)))\n",
    "    if min_eig < 0:\n",
    "        print('need to make the covariance matrix SPD, min_eig =',min_eig)\n",
    "        convariance_mat -= 10*min_eig * np.eye(*convariance_mat.shape)\n",
    "    return convariance_mat\n",
    "\n",
    "\n",
    "def snapshot(sess, epoch, saver,netname='',tag=''):\n",
    "    output_dir = cfg.OUTPUT_DIR\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Store the model snapshot\n",
    "    filename = netname+tag+ '_epoch_{:d}'.format(epoch) + '.ckpt'\n",
    "    filename = os.path.join(output_dir, filename)\n",
    "    saver.save(sess, filename)\n",
    "    print('Wrote snapshot to: {:s}'.format(filename))\n",
    "\n",
    "\n",
    "def split_into_u_var(pred):\n",
    "    ux = tf.slice(pred,[0,0],[-1,1])\n",
    "    uy = tf.slice(pred,[0,1],[-1,1])\n",
    "    uz = tf.slice(pred,[0,2],[-1,1])\n",
    "    # variance must >0\n",
    "    varx = tf.abs(tf.slice(pred,[0,3],[-1,1]))\n",
    "    vary = tf.abs(tf.slice(pred,[0,4],[-1,1]))\n",
    "    varz = tf.abs(tf.slice(pred,[0,5],[-1,1]))\n",
    "    return ux,uy,uz,varx,vary,varz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def slice_layer(dimension, start, end):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call slice(2, 5, 10) as you want to crop on the second dimension\n",
    "    def func(x):\n",
    "        if dimension == 0:\n",
    "            return x[start: end]\n",
    "        if dimension == 1:\n",
    "            return x[:, start: end]\n",
    "        if dimension == 2:\n",
    "            return x[:, :, start: end]\n",
    "        if dimension == 3:\n",
    "            return x[:, :, :, start: end]\n",
    "        if dimension == 4:\n",
    "            return x[:, :, :, :, start: end]\n",
    "    return Lambda(func)\n",
    "\n",
    "\n",
    "def reshape2second_stacks(per_video_db,collapse_user=False,stride=cfg.data_chunk_stride):\n",
    "    \"\"\"reshape from N* *90 into M*max_encoder_seq_length*90\"\"\"\n",
    "    # split into chunks of max_encoder_seq_length seconds\n",
    "    #per_video_db = np.array(np.split(per_video_db,per_video_db.shape[1]/max_encoder_seq_length,axis=1))\n",
    "    max_encoder_seq_length = cfg.running_length\n",
    "    num_encoder_tokens = 3*fps\n",
    "    assert per_video_db.shape[1]>=max_encoder_seq_length*2\n",
    "    nrows = ((per_video_db.shape[1]-max_encoder_seq_length)//stride)+1\n",
    "    new_idx = stride*np.arange(nrows)[:,None] + np.arange(max_encoder_seq_length)\n",
    "    temp = np.zeros((new_idx.shape[0],per_video_db.shape[0],new_idx.shape[1],per_video_db.shape[2]))\n",
    "    for i in range(new_idx.shape[0]):\n",
    "        for j in range(new_idx.shape[1]):\n",
    "            temp[i,:,j,:] = per_video_db[:,new_idx[i,j],:]\n",
    "    per_video_db = temp\n",
    "\n",
    "    # decoder target\n",
    "    # if stride=2, shift by 5 2 seconds to make per_video_db_future 10 seconds away\n",
    "    shift = max_encoder_seq_length//cfg.data_chunk_stride\n",
    "    per_video_db_future = per_video_db[shift:,:,:,:] \n",
    "    per_video_db = per_video_db[:-shift,:]#discard last part, since no future\n",
    "\n",
    "    last_location = per_video_db[:,:,-1,:][:,:,np.newaxis,:]\n",
    "    # decoder input\n",
    "    per_video_db_future_input = np.concatenate((last_location,per_video_db_future[:,:,:-1,:]),axis=2)\n",
    "\n",
    "    if collapse_user:\n",
    "        #mix user and time\n",
    "        #reshape, collapse user dimension\n",
    "        per_video_db = np.reshape(per_video_db,(-1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        per_video_db_future = np.reshape(per_video_db_future,(-1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        per_video_db_future_input = np.reshape(per_video_db_future_input,(-1,max_encoder_seq_length,num_encoder_tokens))\n",
    "    else:\n",
    "        #keep the user dimension in dim 0\n",
    "        #userful for other users' data\n",
    "        per_video_db = per_video_db.transpose((1,0,2,3))\n",
    "        per_video_db_future = per_video_db_future.transpose((1,0,2,3))\n",
    "        per_video_db_future_input = per_video_db_future_input.transpose((1,0,2,3))\n",
    "\n",
    "    return per_video_db,per_video_db_future,per_video_db_future_input\n",
    "\n",
    "\n",
    "def cut_head_or_tail_less_than_1sec(per_video_db):\n",
    "    max_encoder_seq_length = cfg.running_length\n",
    "    num_encoder_tokens = 3*fps\n",
    "    if cfg.cut_data_head:\n",
    "        #cut head to make dividable by seconds\n",
    "        per_video_db = per_video_db[:,per_video_db.shape[1]-per_video_db.shape[1]//fps*fps:,:] \n",
    "    else: #cut tail\n",
    "        per_video_db = per_video_db[:,:per_video_db.shape[1]//fps*fps,:] \n",
    "    return per_video_db\n",
    "\n",
    "\n",
    "def cut_head_or_tail(per_video_db):\n",
    "    max_encoder_seq_length = cfg.running_length\n",
    "    num_encoder_tokens = 3*fps\n",
    "    if cfg.cut_data_head:\n",
    "        #cut head to make dividable by TEN seconds\n",
    "        per_video_db = per_video_db[:,per_video_db.shape[1]-per_video_db.shape[1]//fps//max_encoder_seq_length*fps*max_encoder_seq_length:,:] \n",
    "    else: #cut tail\n",
    "        per_video_db = per_video_db[:,:per_video_db.shape[1]//fps//max_encoder_seq_length*fps*max_encoder_seq_length,:] \n",
    "    return per_video_db\n",
    "\n",
    "\n",
    "def get_time_for_visual(datadb,stride=cfg.data_chunk_stride):\n",
    "    \"\"\"get the exact time for visual input\n",
    "    The time must be matched for both visual and trj inputs.\"\"\"\n",
    "    max_encoder_seq_length = cfg.running_length\n",
    "    num_encoder_tokens = 3*fps\n",
    "    segment_index_tar = OrderedDict()\n",
    "    temp =0\n",
    "    for _video_ind in datadb.keys():\n",
    "        segment_index_tar[_video_ind] = []\n",
    "        num_user_this_vid = datadb[_video_ind]['x'].shape[0]\n",
    "        \n",
    "        per_video_db = np.stack((datadb[_video_ind]['x'],datadb[_video_ind]['y'],datadb[_video_ind]['z']),axis=-1)\n",
    "        # per_video_db = cut_head_or_tail(per_video_db)\n",
    "        per_video_db = cut_head_or_tail_less_than_1sec(per_video_db)\n",
    "        per_video_db = np.reshape(per_video_db,(per_video_db.shape[0],per_video_db.shape[1]//fps,num_encoder_tokens))\n",
    "        if per_video_db.shape[1]<max_encoder_seq_length*2:\n",
    "            print('video %s only has %d seconds. skip in get_time_for_visual()...'%(_video_ind,per_video_db.shape[1]))\n",
    "            continue\n",
    "    \n",
    "        nrows = ((per_video_db.shape[1]-max_encoder_seq_length)//stride)+1\n",
    "        new_idx = stride*np.arange(nrows)[:,None] + np.arange(max_encoder_seq_length)\n",
    "        shift = max_encoder_seq_length/cfg.data_chunk_stride\n",
    "        new_idx = new_idx[:-shift,:]#discard last part, since no future\n",
    "\n",
    "        segment_index_tar[_video_ind] +=list(new_idx)*num_user_this_vid #record how many seconds are there in this video, in order to match the time with viusal input\n",
    "        temp=temp+(new_idx.shape[0])*num_user_this_vid\n",
    "    \n",
    "    # pickle.dump(segment_index_tar,open('./cache/format4/test/stride1_cut_tail/sec_segment_index_tar_test.p','wb'))\n",
    "    # pickle.dump(segment_index_tar,open('./cache/format4/train/stride1_cut_tail/sec_segment_index_tar_train.p','wb'))\n",
    "    return segment_index_tar\n",
    "\n",
    "\n",
    "def get_data(datadb,pick_user=False,num_user=48):\n",
    "    max_encoder_seq_length = cfg.running_length\n",
    "    num_encoder_tokens = 3*fps\n",
    "    if not pick_user:\n",
    "        ### concat all 9 videos and all users\n",
    "        # don't distinguish users or videos during training\n",
    "        _video_db = np.zeros((1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        _video_db_future = np.zeros((1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        _video_db_future_input = np.zeros((1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        for _video_ind in datadb.keys():\n",
    "            per_video_db = np.stack((datadb[_video_ind]['x'],datadb[_video_ind]['y'],datadb[_video_ind]['z']),axis=-1)\n",
    "            # per_video_db = cut_head_or_tail(per_video_db)\n",
    "            per_video_db = cut_head_or_tail_less_than_1sec(per_video_db)\n",
    "            per_video_db = np.reshape(per_video_db,(per_video_db.shape[0],per_video_db.shape[1]//fps,num_encoder_tokens))\n",
    "            if per_video_db.shape[1]<max_encoder_seq_length*2:\n",
    "                print('video %s only has %d seconds. skip...'%(_video_ind,per_video_db.shape[1]))\n",
    "                continue\n",
    "            per_video_db, per_video_db_future, per_video_db_future_input = reshape2second_stacks(per_video_db,collapse_user=True)\n",
    "            print('_video_ind = ',_video_ind,'per_video_db.shape = ',per_video_db.shape)            \n",
    "            _video_db = np.concatenate((_video_db, per_video_db),axis=0)\n",
    "            _video_db_future = np.concatenate((_video_db_future, per_video_db_future),axis=0)\n",
    "            _video_db_future_input = np.concatenate((_video_db_future_input, per_video_db_future_input),axis=0)\n",
    "        return _video_db[1:,:,:], _video_db_future[1:,:,:], _video_db_future_input[1:,:,:]\n",
    "    else:\n",
    "        _video_db_tar = np.zeros((1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        _video_db_future_tar = np.zeros((1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        _video_db_future_input_tar = np.zeros((1,max_encoder_seq_length,num_encoder_tokens))\n",
    "\n",
    "        _video_db_oth = np.zeros((num_user-1,1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        _video_db_future_oth = np.zeros((num_user-1,1,max_encoder_seq_length,num_encoder_tokens))\n",
    "        _video_db_future_input_oth = np.zeros((num_user-1,1,max_encoder_seq_length,num_encoder_tokens))\n",
    "\n",
    "        for _video_ind in datadb.keys(): #every user will be selected as target user and roll over whole dataset\n",
    "            print('_video_ind',_video_ind)\n",
    "            for _target_user in range(datadb[_video_ind]['x'].shape[0]):\n",
    "                print('target user:',_target_user)\n",
    "                # for each video, pick out a target user, split target user and other users\n",
    "                per_video_db = np.stack((datadb[_video_ind]['x'],datadb[_video_ind]['y'],datadb[_video_ind]['z']),axis=-1)\n",
    "                # per_video_db = cut_head_or_tail(per_video_db)\n",
    "                per_video_db = cut_head_or_tail_less_than_1sec(per_video_db)\n",
    "                per_video_db = np.reshape(per_video_db,(per_video_db.shape[0],per_video_db.shape[1]//fps,num_encoder_tokens))\n",
    "                if per_video_db.shape[1]<max_encoder_seq_length*2:\n",
    "                    print('video %s only has %d seconds. skip...'%(_video_ind,per_video_db.shape[1]))\n",
    "                    continue\n",
    "                per_video_db_tar = per_video_db[_target_user,:][np.newaxis,:,:]\n",
    "                per_video_db_oth = np.delete(per_video_db,_target_user,axis=0)\n",
    "                if per_video_db_oth.shape[0]<num_user-1:\n",
    "                    for concat_ind in range(per_video_db_oth.shape[0],num_user-1):\n",
    "                        duplicate_ind = np.random.randint(per_video_db_oth.shape[0])\n",
    "                        # print('duplicate_ind:',duplicate_ind)\n",
    "                        temp = per_video_db_oth[duplicate_ind,:][np.newaxis,:]\n",
    "                        per_video_db_oth = np.concatenate([per_video_db_oth,temp],axis=0)\n",
    "                try:\n",
    "                    assert per_video_db_oth.shape[0]==num_user-1\n",
    "                except:\n",
    "                    pdb.set_trace()\n",
    "                print('has %d other users'%(num_user-1))\n",
    "\n",
    "                per_video_db_tar, per_video_db_future_tar, per_video_db_future_input_tar = reshape2second_stacks(per_video_db_tar,collapse_user=True)\n",
    "                per_video_db_oth, per_video_db_future_oth, per_video_db_future_input_oth = reshape2second_stacks(per_video_db_oth,collapse_user=False)\n",
    "                # print('_video_ind = ',_video_ind,'per_video_db.shape = ',per_video_db.shape)            \n",
    "                # print('_video_ind = ',_video_ind,'per_video_db_tar.shape = ',per_video_db_tar.shape)            \n",
    "                # print('_video_ind = ',_video_ind,'per_video_db_oth.shape = ',per_video_db_oth.shape)            \n",
    "                _video_db_tar = np.concatenate((_video_db_tar, per_video_db_tar),axis=0)\n",
    "                _video_db_future_tar = np.concatenate((_video_db_future_tar, per_video_db_future_tar),axis=0)\n",
    "                _video_db_future_input_tar = np.concatenate((_video_db_future_input_tar, per_video_db_future_input_tar),axis=0)\n",
    "\n",
    "                _video_db_oth = np.concatenate((_video_db_oth, per_video_db_oth),axis=1)\n",
    "                _video_db_future_oth = np.concatenate((_video_db_future_oth, per_video_db_future_oth),axis=1)\n",
    "                _video_db_future_input_oth = np.concatenate((_video_db_future_input_oth, per_video_db_future_input_oth),axis=1)\n",
    "\n",
    "\n",
    "        return _video_db_tar[1:,:,:], _video_db_future_tar[1:,:,:], _video_db_future_input_tar[1:,:,:], \\\n",
    "                _video_db_oth[:,1:,:,:], _video_db_future_oth[:,1:,:,:], _video_db_future_input_oth[:,1:,:,:]\n",
    "\n",
    "\n",
    "\n",
    "# get target user data and other user's data\n",
    "# _video_db_tar, _video_db_future_tar, _video_db_future_input_tar, \\\n",
    "# _video_db_oth,_video_db_future_oth,_video_db_future_input_oth = get_data(datadb,pick_user=True)\n",
    "# # # cache data\n",
    "# pickle.dump(_video_db_tar,open('./cache/format5_tsinghua_by_sec_interp/train/_video_db_tar.p','wb'))\n",
    "# pickle.dump(_video_db_future_tar,open('./cache/format5_tsinghua_by_sec_interp/train/_video_db_future_tar.p','wb'))\n",
    "# pickle.dump(_video_db_future_input_tar,open('./cache/format5_tsinghua_by_sec_interp/train/_video_db_future_input_tar.p','wb'))\n",
    "# pickle.dump(_video_db_oth,open('./cache/format5_tsinghua_by_sec_interp/train/_video_db_oth.p','wb'))\n",
    "# pickle.dump(_video_db_future_oth,open('./cache/format5_tsinghua_by_sec_interp/train/_video_db_future_oth.p','wb'))\n",
    "# pickle.dump(_video_db_future_input_oth,open('./cache/format5_tsinghua_by_sec_interp/train/_video_db_future_input_oth.p','wb'))\n",
    "\n",
    "\n",
    "\n",
    "# #TODO!!!!!!!!!!!!!!\n",
    "# save2hdf5('./cache/'+dataformat+'/train/stride1_cut_tail/_video_db_tar.h5','_video_db_tar',_video_db_tar)\n",
    "# save2hdf5('./cache/'+dataformat+'/train/stride1_cut_tail/_video_db_future_tar.h5','_video_db_future_tar',_video_db_future_tar)\n",
    "# save2hdf5('./cache/'+dataformat+'/train/stride1_cut_tail/_video_db_future_input_tar.h5','_video_db_future_input_tar',_video_db_future_input_tar)\n",
    "# save2hdf5('./cache/'+dataformat+'/train/stride1_cut_tail/_video_db_oth.h5','_video_db_oth',_video_db_oth)\n",
    "# save2hdf5('./cache/'+dataformat+'/train/stride1_cut_tail/_video_db_future_oth.h5','_video_db_future_oth',_video_db_future_oth)\n",
    "# save2hdf5('./cache/'+dataformat+'/train/stride1_cut_tail/_video_db_future_input_oth.h5','_video_db_future_input_oth',_video_db_future_input_oth)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_shuffle_index(data_length):\n",
    "    index_shuf = range(data_length)\n",
    "    shuffle(index_shuf)\n",
    "    return index_shuf\n",
    "\n",
    "def shuffle_data(index_shuf,list1):\n",
    "    list1_shuf = [list1[i] for i in index_shuf]\n",
    "    return np.array(list1_shuf)\n",
    "\n",
    "def get_gt_target_xyz(y):\n",
    "    if y.shape[-1]==3:\n",
    "        assert len(y.shape)==4\n",
    "        target_x = y[:,:,:,0]\n",
    "        target_y = y[:,:,:,1]\n",
    "        target_z = y[:,:,:,2]\n",
    "    elif y.shape[-1]==90:\n",
    "        assert len(y.shape)==3\n",
    "        target_x = y[:,:,0::3]\n",
    "        target_y = y[:,:,1::3]\n",
    "        target_z = y[:,:,2::3]\n",
    "    gt_mean_x = np.mean(target_x, axis=-1)[:,:,np.newaxis]\n",
    "    gt_var_x = np.var(target_x, axis=-1)[:,:,np.newaxis]\n",
    "    gt_mean_y = np.mean(target_y, axis=-1)[:,:,np.newaxis]\n",
    "    gt_var_y = np.var(target_y, axis=-1)[:,:,np.newaxis]\n",
    "    gt_mean_z = np.mean(target_z, axis=-1)[:,:,np.newaxis]\n",
    "    gt_var_z = np.var(target_z, axis=-1)[:,:,np.newaxis]\n",
    "    return np.concatenate((gt_mean_x,gt_mean_y,gt_mean_z,gt_var_x,gt_var_y,gt_var_z),axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_gt_target_xyz_oth(y):\n",
    "    # for others data\n",
    "    # assert y.shape==(11040, 20, 47, 30, 3)\n",
    "    target_x = y[:,:,:,:,0]\n",
    "    target_y = y[:,:,:,:,1]\n",
    "    target_z = y[:,:,:,:,2]\n",
    "    gt_mean_x = np.mean(target_x, axis=-1)[:,:,:,np.newaxis]\n",
    "    gt_var_x = np.var(target_x, axis=-1)[:,:,:,np.newaxis]\n",
    "    gt_mean_y = np.mean(target_y, axis=-1)[:,:,:,np.newaxis]\n",
    "    gt_var_y = np.var(target_y, axis=-1)[:,:,:,np.newaxis]\n",
    "    gt_mean_z = np.mean(target_z, axis=-1)[:,:,:,np.newaxis]\n",
    "    gt_var_z = np.var(target_z, axis=-1)[:,:,:,np.newaxis]\n",
    "    return np.concatenate((gt_mean_x,gt_mean_y,gt_mean_z,gt_var_x,gt_var_y,gt_var_z),axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _save_theta_phi_index(reshape_datadb):\n",
    "    def _theta_phi_index_for_onehot(_video_db,name='_video_db',data_format=1):\n",
    "        #shape: (11040, 10, 1, 30, 3)\n",
    "        if len(_video_db.shape)==5:\n",
    "            x_list = _video_db[:,:,0,:,0]\n",
    "            y_list = _video_db[:,:,0,:,1]\n",
    "            z_list = _video_db[:,:,0,:,2]\n",
    "        else:\n",
    "            x_list = _video_db[:,:,:,0]\n",
    "            y_list = _video_db[:,:,:,1]\n",
    "            z_list = _video_db[:,:,:,2]\n",
    "\n",
    "        theta_list, phi_list = xyz2thetaphi(x_list,y_list,z_list)\n",
    "\n",
    "        bin_size=10\n",
    "        theta_list2 = theta_list+np.pi\n",
    "        theta_index = np.floor(theta_list2/np.pi*180/bin_size)\n",
    "        theta_index[theta_index==360/bin_size]-=1\n",
    "\n",
    "        phi_index = np.floor(phi_list/np.pi*180/bin_size)\n",
    "        phi_index[phi_index==180/bin_size]-=1\n",
    "        pickle.dump(theta_index,open('./cache/format'+str(data_format)+'/'+name+'_theta_index_exp'+str(experiment)+'.p','wb'))    \n",
    "        pickle.dump(phi_index,open('./cache/format'+str(data_format)+'/'+name+'_phi_index_exp'+str(experiment)+'.p','wb'))    \n",
    "\n",
    "    # format 1\n",
    "    _theta_phi_index_for_onehot(_video_db,name='_video_db',data_format=1)\n",
    "    _theta_phi_index_for_onehot(_video_db_future_input,name='_video_db_future_input',data_format=1)\n",
    "    _theta_phi_index_for_onehot(_video_db_future,name='_video_db_future',data_format=1)\n",
    "    # format 2\n",
    "    _theta_phi_index_for_onehot(_video_db,name='_video_db_tar',data_format=2)\n",
    "    _theta_phi_index_for_onehot(_video_db_future_input,name='_video_db_future_input_tar',data_format=2)\n",
    "    _theta_phi_index_for_onehot(_video_db_future,name='_video_db_future_tar',data_format=2)\n",
    "\n",
    "\n",
    "\n",
    "def _create_one_hot(theta_index,phi_index,bin_size=10,vector=False):\n",
    "    #one-hot matrix -> reshape into vector\n",
    "    one_hot = np.zeros((theta_index.shape[0],theta_index.shape[1],theta_index.shape[2],(360/bin_size),(180/bin_size)))\n",
    "    #any faster ways?\n",
    "    for ii in range(theta_index.shape[0]):\n",
    "        for jj in range(theta_index.shape[1]):\n",
    "            for kk in range(theta_index.shape[2]):\n",
    "                one_hot[ii,jj,kk,int(theta_index[ii,jj,kk]),int(phi_index[ii,jj,kk])]=1\n",
    "    if vector:\n",
    "        one_hot = one_hot.reshape((theta_index.shape[0],theta_index.shape[1],theta_index.shape[2],-1))\n",
    "\n",
    "    # # one hot encode using keras\n",
    "    # encoded = to_categorical(data)\n",
    "    # pickle.dump(one_hot,open('./cache/'+name+'_one_hot_exp'+str(experiment)+'.p','wb')) ##too large, should save as sparse\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\n",
    "def rand_sample_ind(total_num_samples,num_testing_sample,batch_size,validation_ratio=0.1):\n",
    "    \"\"\"ensure dividable by batch size\"\"\"\n",
    "    # the num of training samples should be dividable by batch_size (sometimes error msg)\n",
    "    # should use fit_generator() instead of fit() in the future\n",
    "    x2 = int((total_num_samples-num_testing_sample)/batch_size*validation_ratio)\n",
    "    m1 = int((1-validation_ratio)/validation_ratio*x2*batch_size)\n",
    "    m2 = int(x2*batch_size)\n",
    "    # num_validation = (total_num_samples-num_testing_sample-num_training)/batch_size*batch_size\n",
    "    # sample_ind = random.sample(xrange(total_num_samples-num_testing_sample),num_training+num_validation)\n",
    "    sample_ind = random.sample(range(total_num_samples-num_testing_sample),m1+m2)\n",
    "    return sample_ind\n",
    "\n",
    "\n",
    "def rand_sample(data,sample_ind):\n",
    "    data = [ data[i] for i in sorted(sample_ind)]\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _normalize_data(data):\n",
    "    \"\"\"normalize data into N(0,1)\"\"\"\n",
    "    # if data has mulitple dimensions, np.mean() will mean across all dims\n",
    "    return (data-np.mean(data))/np.std(data)\n",
    "\n",
    "\n",
    "\n",
    "def _insert_end_of_stroke(per_video_db,original_per_video_db):\n",
    "    \"\"\"create fake end of stroke signals\n",
    "    eos will be set to 1 if:\n",
    "    1) in the beginning and end of the whole trj\n",
    "    2) whenever the theta has larger than pi changes \n",
    "       (~2pi change from pi to -pi or vice versa)\n",
    "    \"\"\"\n",
    "    eos = np.zeros((per_video_db['theta'].shape[0],per_video_db['theta'].shape[1]))\n",
    "    eos[:,0]=1\n",
    "    eos[:,-1]=1\n",
    "    #note that there are near 2pi changes in theta\n",
    "    #we used +-pi as the thereshold\n",
    "    if cfg.use_residual_input and not cfg.normalize_residual:\n",
    "        eos[:,1:][per_video_db['theta'][:,1:]>np.pi]=1\n",
    "        eos[:,1:][per_video_db['theta'][:,1:]<-np.pi]=1\n",
    "        ##change from diff to real location at the eos==1 \n",
    "        # per_video_db['theta'][:,1:][eos[:,1:]==1] = original_per_video_db['theta'][:,1:][eos[:,1:]==1]\n",
    "        # per_video_db['phi'][:,1:][eos[:,1:]==1] = original_per_video_db['phi'][:,1:][eos[:,1:]==1]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    per_video_db['eos'] = eos\n",
    "\n",
    "def data_to_step_residual(datadb):\n",
    "    \"\"\"convert the input data into step-residual: \n",
    "    x_t-x_{t-1}, x_{t+1}-x_t ...\"\"\"\n",
    "    # in handwritten sequence generation, the first location is the real location\n",
    "    datadb_res = {}\n",
    "    for ii in datadb.keys():\n",
    "        datadb_res[ii]={}\n",
    "        for key in datadb[ii].keys():\n",
    "            datadb_res[ii][key] = np.hstack([np.expand_dims(datadb[ii][key][:,0],1),datadb[ii][key][:,1:]-datadb[ii][key][:,:-1]])\n",
    "        if cfg.normalize_residual:\n",
    "            for key in datadb_res[ii].keys():\n",
    "                datadb_res[ii][key] = _normalize_data(datadb_res[ii][key])\n",
    "        \n",
    "        if cfg.predict_eos:\n",
    "            #insert eos\n",
    "            _insert_end_of_stroke(datadb_res[ii],datadb[ii]) #seems dict doesn't have to be returned...\n",
    "    return datadb_res\n",
    "\n",
    "\n",
    "def _insert_end_of_stroke2(datadb):\n",
    "    \"\"\"\n",
    "       for datadb that is not residual! \n",
    "    \"\"\"\n",
    "    assert cfg.use_residual_input==False\n",
    "    for ii in datadb.keys():\n",
    "        per_video_db = datadb[ii]\n",
    "        eos = np.zeros((per_video_db['theta'].shape[0],per_video_db['theta'].shape[1]))\n",
    "        eos[:,0]=1\n",
    "        eos[:,-1]=1\n",
    "        diff = per_video_db['theta'][:,1:]-per_video_db['theta'][:,:-1]\n",
    "        eos[:,1:][diff>np.pi]=1\n",
    "        eos[:,1:][diff<-np.pi]=1 \n",
    "        datadb[ii]['eos'] = eos\n",
    "    return datadb\n",
    "\n",
    "def subsample_datadb(datadb,subsample_factor=5):\n",
    "    \"\"\"subsample datadb into lower FPS\"\"\"\n",
    "    # to introduce more variations\n",
    "    for ii in datadb.keys():\n",
    "        for kk in datadb[ii].keys():\n",
    "            datadb[ii][kk] = datadb[ii][kk][:,0::subsample_factor]\n",
    "    return datadb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_mu_std(datadb,vid_ind=cfg.test_video_ind):\n",
    "    \"\"\"for denormalization\"\"\"\n",
    "    std1 = np.std(datadb[vid_ind]['theta'])\n",
    "    mu1 = np.mean(datadb[vid_ind]['theta'])\n",
    "\n",
    "    std2 = np.std(datadb[vid_ind]['phi'])\n",
    "    mu2 = np.mean(datadb[vid_ind]['phi'])\n",
    "    return mu1,std1,mu2,std2\n",
    "\n",
    "\n",
    "def _denormalize_data(output,mu1,std1,mu2,std2):\n",
    "    \"\"\"de-normalize the predicted output\"\"\"\n",
    "    out1 = output[:,:,0]\n",
    "    out2 = output[:,:,1]\n",
    "    #note that there are near 2pi changes in theta\n",
    "    out = np.stack([out1*std1+mu1,\n",
    "                    out2*std2+mu2],-1)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##simplied from https://github.com/snowkylin/rnn-handwriting-generation/blob/master/model.py\n",
    "def sample(pi, mu1, mu2, sigma1, sigma2, rho, num_mixtures=20):\n",
    "    \"\"\"cg: sample from predicted mixture density\"\"\"\n",
    "    # deleted the 3rd dimension since we didn't predict the End of Stroke\n",
    "    x = np.zeros([cfg.batch_size, 1, 2], np.float32)\n",
    "    strokes = np.zeros([cfg.batch_size, 2], dtype=np.float32)\n",
    "    r = np.random.rand()\n",
    "    accu = 0\n",
    "    for batch_ind in range(cfg.batch_size):\n",
    "        for m in range(num_mixtures):\n",
    "            accu += pi[batch_ind, m]\n",
    "            if accu > r:\n",
    "                x[batch_ind, 0, 0:2] = np.random.multivariate_normal(\n",
    "                    [mu1[batch_ind, m], mu2[batch_ind, m]],\n",
    "                    [[np.square(sigma1[batch_ind, m]), rho[batch_ind, m] * sigma1[batch_ind, m] * sigma2[batch_ind, m]],\n",
    "                     [rho[batch_ind, m] * sigma1[batch_ind, m] * sigma2[batch_ind, m], np.square(sigma2[batch_ind, m])]]\n",
    "                )\n",
    "                break\n",
    "\n",
    "        strokes[batch_ind, :] = x[batch_ind, 0, :]\n",
    "    return strokes\n",
    "\n",
    "\n",
    "\n",
    "def data_visualization(datadb):\n",
    "    def plot_xyz(datadb,video_ind,user_ind,start=0,end=-1):\n",
    "        plt.plot(datadb[video_ind]['x'][user_ind,start:end])\n",
    "        plt.plot(datadb[video_ind]['y'][user_ind,start:end])\n",
    "        plt.plot(datadb[video_ind]['z'][user_ind,start:end])\n",
    "        plt.show()\n",
    "\n",
    "    def plot_phi_theta(datadb,video_ind,user_ind,start=0,end=-1):\n",
    "        plt.plot(datadb[video_ind]['theta'][user_ind,start:end])\n",
    "        plt.plot(datadb[video_ind]['phi'][user_ind,start:end])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_all_users(datadb,video_ind,key,start=0,end=-1):\n",
    "        for ii in range(datadb[video_ind][key].shape[0]):\n",
    "            plt.plot(datadb[video_ind][key][ii,start:end])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def get_random_ind():\n",
    "        video_ind = np.random.randint(9)\n",
    "        key = datadb[video_ind].keys()[0]\n",
    "        user_ind = np.random.randint(datadb[video_ind][key].shape[0])\n",
    "        rand_s = np.random.randint(datadb[video_ind][key].shape[1])\n",
    "        print('video_ind',video_ind,'user_ind',user_ind,'random start',rand_s)\n",
    "        return video_ind,user_ind,rand_s\n",
    "\n",
    "    # for video_ind in datadb.keys():\n",
    "    #     for user_ind in range(datadb[video_ind]['x'].shape[0]):\n",
    "    #         plot_xyz(video_ind,user_ind)\n",
    "    #         pdb.set_trace()\n",
    "    #         plt.cla()\n",
    "\n",
    "    while True:\n",
    "        #random select\n",
    "        video_ind,user_ind,rand_s = get_random_ind()\n",
    "        plt.figure('xyz')\n",
    "        plot_xyz(video_db_xyz,video_ind,user_ind,start=rand_s,end=rand_s+500)\n",
    "        plt.figure('theta_phi')\n",
    "        plot_phi_theta(video_db_thetaphi,video_ind,user_ind,start=rand_s,end=rand_s+500)\n",
    "        pdb.set_trace()\n",
    "        plt.cla()\n",
    "\n",
    "\n",
    "    while True:\n",
    "        video_ind,user_ind,rand_s = get_random_ind()\n",
    "        # plot_all_users(video_db_thetaphi,video_ind,'phi',start=rand_s,end=rand_s+500)\n",
    "        plot_all_users(video_db_xyz,video_ind,'y',start=rand_s,end=rand_s+500)\n",
    "        pdb.set_trace()\n",
    "        plt.cla()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "def _VAR(train,test=None):\n",
    "    model = VAR(train)\n",
    "    model_fit = model.fit() #maxlags=299, ic='aic')\n",
    "    print('Lag: %s' % model_fit.k_ar)\n",
    "    if test!=None:\n",
    "        predictions = model_fit.forecast(train[-10:,:],len(test))\n",
    "        error = mean_squared_error(test, predictions)\n",
    "        print('Test MSE: %.3f' % error)\n",
    "    else:\n",
    "        predictions = model_fit.forecast(train[-10:,:],len(train))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "def _linear_model_residual_input_(data,data_future,mode='presistence'):\n",
    "    def _get_it(data,data_future,mode):   \n",
    "        residual_input = np.zeros_like(data_future)\n",
    "        prediction_future = np.zeros_like(data_future) #predictions using mode\n",
    "        data = data.reshape(-1,10,30,3)\n",
    "        data_future = data_future.reshape(-1,10,30,3)\n",
    "        for ii in range(residual_input.shape[0]):\n",
    "            train = data[ii,:,:,:].reshape(-1,3)\n",
    "            gt = data_future[ii,:,:,:].reshape(-1,3)\n",
    "            # if np.sum(train,0)[2]==-300: var will have problem!!!\n",
    "            #     predictions = np.repeat(data[ii,-1,-1,:].reshape(1,3),300,axis=0)\n",
    "            #     continue\n",
    "            if mode=='var':\n",
    "                try:\n",
    "                    predictions = _VAR(train=train,test=None)\n",
    "                except:\n",
    "                    predictions = np.repeat(data[ii,-1,-1,:].reshape(1,3),300,axis=0)                    \n",
    "            elif mode=='presistence':\n",
    "                predictions = np.repeat(data[ii,-1,-1,:].reshape(1,3),300,axis=0)\n",
    "            residual = (gt-predictions).reshape(1,10,90)\n",
    "            residual_input[ii,:] = residual\n",
    "            prediction_future[ii,:] = predictions.reshape(1,10,90)\n",
    "        return residual_input,prediction_future\n",
    "\n",
    "    # if data.shape[0]==num_user-1: #oth\n",
    "    if data.shape[0]==47:\n",
    "        residual_input = np.zeros_like(data_future)\n",
    "        prediction_future = np.zeros_like(data_future)\n",
    "        for user_ind in range(data.shape[0]):\n",
    "            print('user ind,',user_ind)\n",
    "            data_temp = data[user_ind,:]\n",
    "            data_future_temp = data_future[user_ind,:]\n",
    "            residual_input_temp,prediction_future_temp = _get_it(data_temp,data_future_temp,mode)\n",
    "            residual_input[user_ind,:] = residual_input_temp\n",
    "            prediction_future[user_ind,:] = prediction_future_temp\n",
    "    else:#tar\n",
    "        residual_input,prediction_future = _get_it(data,data_future,mode)\n",
    "    return residual_input,prediction_future\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_k_neighbours(target_user_last_sec, other_users_this_sec, k):\n",
    "    \"\"\"return all neighbours for the target user\"\"\"\n",
    "    num_others =  other_users.shape[0] #num_othersx90\n",
    "    fps = 30\n",
    "    distance = (other_users_this_sec - target_user_last_sec).reshape(num_others,fps,3)\n",
    "    distance = np.sqrt(np.sum(distance**2,axis=-1))\n",
    "    ave_distance = np.mean(distance,axis=1)\n",
    "    neighbor_ind = ave_distance.argsort()[:k]\n",
    "    return neighbor_ind\n",
    "\n",
    "\n",
    "def find_k_neighbours_TF(target_user_last_sec, other_users_this_sec, k):\n",
    "    # tensorflow \n",
    "    # on mean and variance batchx1x6, batchx1xnum_othersx6\n",
    "    \"\"\"return all neighbours for the target user\"\"\"\n",
    "    num_others =  other_users_this_sec.shape[-2].value #num_othersx90\n",
    "    fps = 30\n",
    "    distance = tf.reshape((other_users_this_sec[:,0,:,:] - target_user_last_sec[:,0,:]),[-1,num_others,6])\n",
    "    ave_distance = tf.reduce_sum(distance,axis=-1)\n",
    "    _,neighbor_ind = tf.nn.top_k(ave_distance,k=k,sorted=True,name=None)\n",
    "\n",
    "    # # nearest k points\n",
    "    # _, top_k_indices = tf.nn.top_k(tf.negative(distance), k=k)\n",
    "    # top_k_label = tf.gather(y_data_train, top_k_indices)\n",
    "\n",
    "    # sum_up_predictions = tf.reduce_sum(top_k_label, axis=1)\n",
    "    # prediction = tf.argmax(sum_up_predictions, axis=1)\n",
    "    return neighbor_ind\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save2hdf5(path_name,key,data_to_store):\n",
    "    hf = h5py.File(path_name, 'w')\n",
    "    hf.create_dataset(key,data=data_to_store)\n",
    "    hf.close()\n",
    "\n",
    "def load_h5(path_name,key):\n",
    "    #load\n",
    "    hf = h5py.File(path_name, 'r')\n",
    "    print(hf.keys())\n",
    "    data = hf.get(key)\n",
    "    data = np.array(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def saliency2h5():\n",
    "    #Prepare saliency data (one pickle for each video) (cutted tail less than one second) into h5. \n",
    "    filelist = glob.glob('/scratch/cl2840/360video/temp/saliency_input/input*p')\n",
    "    for ii in range(1,len(filelist)):\n",
    "        temp = pickle.load(open(filelist[ii],'rb'))\n",
    "        save2hdf5(filelist[ii][:-2]+'.h5','source_surround',temp)\n",
    "\n",
    "\n",
    "def get_random_k_other_users(_video_db_oth):\n",
    "    \"\"\"pretrained from shanghai and test it on tsinghua\"\"\"\n",
    "    # since tsinghua dataset has 47 other user, shanghai has 33 other users. \n",
    "    # we randomly select 33 other users from the 47\n",
    "    new = np.zeros((_video_db_oth.shape[0],_video_db_oth.shape[1],33,30,3))\n",
    "    for ii in range(_video_db_oth.shape[0]):\n",
    "        index = np.arange(47)\n",
    "        random.shuffle(index)\n",
    "        index = index[:33]\n",
    "        new[ii,:] = _video_db_oth[ii,:][:,index,:,:].copy()\n",
    "    return new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
